{"cells":[{"cell_type":"markdown","id":"6b4d2385","metadata":{},"source":["## Loading Data from Google Cloud Storage (GCS) and Schema Alignment"]},{"cell_type":"code","execution_count":1,"id":"bdcbee61","metadata":{},"outputs":[],"source":["from pyspark.sql import SparkSession, functions as F, types as T\n","import unicodedata\n","from functools import reduce\n","from pyspark.ml import Pipeline\n","from pyspark.ml.feature import StringIndexer, OneHotEncoder, Imputer, VectorAssembler\n","from pyspark.sql.types import DoubleType"]},{"cell_type":"code","execution_count":2,"id":"6d5ff153","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["25/11/04 05:24:00 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n","                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["DF columns: ['STATION', 'DATE', 'SOURCE', 'LATITUDE', 'LONGITUDE', 'ELEVATION', 'NAME', 'REPORT_TYPE', 'CALL_SIGN', 'QUALITY_CONTROL', 'WND', 'CIG', 'VIS', 'TMP', 'DEW', 'SLP', 'AA1', 'AB1', 'AE1', 'AO1']\n","Required : ['date', 'latitude', 'longitude', 'elevation', 'wnd', 'cig', 'vis', 'dew', 'slp', 'tmp']\n","Present   : []\n","Missing   : ['date', 'latitude', 'longitude', 'elevation', 'wnd', 'cig', 'vis', 'dew', 'slp', 'tmp']\n","Files read from: gs://dsa5208-mllib-proj/2024/*.csv\n"]},{"name":"stderr","output_type":"stream","text":["[Stage 3:======================================================>(826 + 1) / 827]\r"]},{"name":"stdout","output_type":"stream","text":["Total rows: 130222106\n","Columns kept: ['date', 'latitude', 'longitude', 'elevation', 'wnd', 'cig', 'vis', 'dew', 'slp', 'tmp']\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["spark = (\n","    SparkSession.builder\n","    .appName(\"Read-CSV-Subset-GCS\")\n","    .getOrCreate()\n",")\n","spark.sparkContext.setLogLevel(\"WARN\")\n","\n","GCS_PATH = \"gs://dsa5208-mllib-proj/2024/*.csv\" \n","REQUIRED_COLS = [\n","    'DATE','LATITUDE','LONGITUDE','ELEVATION','WND','CIG','VIS','DEW','SLP','TMP'\n","]\n","\n","def canon(name: str) -> str:\n","    s = unicodedata.normalize(\"NFKC\", name or \"\")\n","    s = s.replace(\"\\ufeff\",\"\").strip()\n","    s = \" \".join(s.split())\n","    return s.replace(\" \", \"_\").lower()\n","\n","df_all = (\n","    spark.read.format(\"csv\")\n","    .option(\"header\", True)\n","    .option(\"inferSchema\", False)\n","    .option(\"multiLine\", False)\n","    .option(\"recursiveFileLookup\", True)\n","    .option(\"mode\", \"PERMISSIVE\")\n","    .option(\"columnNameOfCorruptRecord\", \"_corrupt\")\n","    .load(GCS_PATH) \n",")\n","\n","REQUIRED_COLS = [canon(c) for c in REQUIRED_COLS]\n","\n","print(\"DF columns:\", df_all.columns[:20])  # first 20\n","print(\"Required :\", REQUIRED_COLS)\n","present = [c for c in REQUIRED_COLS if c in df_all.columns]\n","missing = [c for c in REQUIRED_COLS if c not in df_all.columns]\n","print(\"Present   :\", present)\n","print(\"Missing   :\", missing)\n","\n","canon_cols = [canon(c) for c in df_all.columns]\n","df_all = df_all.toDF(*canon_cols)\n","\n","required_set = set(REQUIRED_COLS)\n","present = [c for c in REQUIRED_COLS if c in df_all.columns]\n","missing = [c for c in REQUIRED_COLS if c not in df_all.columns]\n","\n","for c in missing:\n","    df_all = df_all.withColumn(c, F.lit(None).cast(T.StringType()))\n","\n","df_subset = df_all.select(*REQUIRED_COLS)\n","\n","print(f\"Files read from: {GCS_PATH}\")\n","print(f\"Total rows: {df_subset.count()}\")\n","print(\"Columns kept:\", df_subset.columns)\n","if missing:\n","    print(\"Missing columns (added as NULL):\", missing)\n"]},{"cell_type":"code","execution_count":3,"id":"00e7d9e9","metadata":{"scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------------------+--------+---------+---------+--------------+-----------+------------+-------+-------+-------+\n","|date               |latitude|longitude|elevation|wnd           |cig        |vis         |dew    |slp    |tmp    |\n","+-------------------+--------+---------+---------+--------------+-----------+------------+-------+-------+-------+\n","|2024-01-01T00:00:00|34.7728 |-87.6399 |161.5    |211,1,H,0018,1|99999,9,9,N|999999,9,9,9|+9999,9|99999,9|+0105,1|\n","|2024-01-01T00:05:00|34.7728 |-87.6399 |161.5    |214,1,H,0017,1|99999,9,9,N|999999,9,9,9|+9999,9|99999,9|+0100,1|\n","|2024-01-01T00:10:00|34.7728 |-87.6399 |161.5    |212,1,H,0017,1|99999,9,9,N|999999,9,9,9|+9999,9|99999,9|+0088,1|\n","+-------------------+--------+---------+---------+--------------+-----------+------------+-------+-------+-------+\n","only showing top 3 rows\n","\n"]}],"source":["df_f = df_subset\n","df_f.show(3, truncate=False)"]},{"cell_type":"markdown","id":"12d9b0bc","metadata":{},"source":["## Parsing and Splitting Multi-Value Observation Columns"]},{"cell_type":"code","execution_count":4,"id":"6ad8e36f","metadata":{},"outputs":[],"source":["# Generic splitter for unsigned comma-separated fields (e.g., WND, CIG, VIS, SLP)\n","def split_column(df, col, new_names, casts=None):\n","    arr = F.split(F.col(col).cast(\"string\"), \",\")\n","    for i, name in enumerate(new_names):\n","        v = F.trim(F.when(F.size(arr) > i, arr.getItem(i)))\n","        if casts and i < len(casts) and casts[i]:\n","            v = v.cast(casts[i])\n","        df = df.withColumn(f\"{col}_{name}\", v)\n","    return df.drop(col)\n","\n","# For TMP/DEW: signed integer in tenths of Â°C + QC\n","def split_signed_tenths(df, col, value_name=\"C\", qc_name=\"q\"):\n","    # build expressions that reference `col`\n","    arr  = F.split(F.col(col).cast(\"string\"), \",\")\n","    raw  = F.trim(F.when(F.size(arr) > 0, arr.getItem(0)))\n","    qc   = F.trim(F.when(F.size(arr) > 1, arr.getItem(1))).cast(\"int\")\n","\n","    tenths = F.regexp_extract(raw, r'^[+-]?\\d+', 0).cast(\"int\")\n","    tenths = F.when(tenths.isNull() | (F.abs(tenths) == 9999), None).otherwise(tenths)\n","    degC   = (tenths / 10.0).cast(\"double\")\n","\n","    # add columns while `col` still exists, then drop it\n","    df = df.withColumn(f\"{col}_{value_name}\", degC) \\\n","           .withColumn(f\"{col}_{qc_name}\", qc)\n","    return df.drop(col)\n","\n","# Unsigned multi-part fields\n","df_f = split_column(df_f, \"wnd\", [\"dir\",\"q1\",\"type\",\"speed\",\"q2\"], [\"int\",\"int\",\"string\",\"int\",\"int\"])\n","df_f = split_column(df_f, \"cig\", [\"height\",\"q\"], [\"int\",\"int\"])\n","df_f = split_column(df_f, \"vis\", [\"dist\",\"q1\"], [\"int\",\"int\"])\n","df_f = split_column(df_f, \"slp\", [\"val\",\"q\"], [\"int\",\"int\"])\n","\n","# Signed & scaled fields\n","df_f = split_signed_tenths(df_f, \"tmp\", value_name=\"cel\", qc_name=\"q\")   # -> TMP_cel, TMP_q\n","df_f = split_signed_tenths(df_f, \"dew\", value_name=\"cel\", qc_name=\"q\")   # -> DEW_cel, DEW_q\n","\n","# Signed single-value numeric columns\n","df_f = (df_f\n","  .withColumn(\"latitude\",  F.col(\"latitude\").cast(\"double\"))\n","  .withColumn(\"longitude\", F.col(\"longitude\").cast(\"double\"))\n","  .withColumn(\"elevation\", F.col(\"elevation\").cast(\"double\")))\n"]},{"cell_type":"code","execution_count":5,"id":"6776b847","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------------------+--------+---------+---------+-------+------+--------+---------+------+----------+-----+--------+------+-------+-----+-------+-----+-------+-----+\n","|date               |latitude|longitude|elevation|wnd_dir|wnd_q1|wnd_type|wnd_speed|wnd_q2|cig_height|cig_q|vis_dist|vis_q1|slp_val|slp_q|tmp_cel|tmp_q|dew_cel|dew_q|\n","+-------------------+--------+---------+---------+-------+------+--------+---------+------+----------+-----+--------+------+-------+-----+-------+-----+-------+-----+\n","|2024-01-01T00:00:00|34.7728 |-87.6399 |161.5    |211    |1     |H       |18       |1     |99999     |9    |999999  |9     |99999  |9    |10.5   |1    |NULL   |9    |\n","|2024-01-01T00:05:00|34.7728 |-87.6399 |161.5    |214    |1     |H       |17       |1     |99999     |9    |999999  |9     |99999  |9    |10.0   |1    |NULL   |9    |\n","|2024-01-01T00:10:00|34.7728 |-87.6399 |161.5    |212    |1     |H       |17       |1     |99999     |9    |999999  |9     |99999  |9    |8.8    |1    |NULL   |9    |\n","+-------------------+--------+---------+---------+-------+------+--------+---------+------+----------+-----+--------+------+-------+-----+-------+-----+-------+-----+\n","only showing top 3 rows\n","\n"]}],"source":["df_f.show(3, truncate=False)"]},{"cell_type":"code","execution_count":6,"id":"1329798d","metadata":{"scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------------------+--------+---------+-------+-----+\n","|date               |latitude|longitude|tmp_cel|tmp_q|\n","+-------------------+--------+---------+-------+-----+\n","|2024-01-02T12:35:00|34.7728 |-87.6399 |-0.7   |1    |\n","|2024-01-02T12:40:00|34.7728 |-87.6399 |-0.5   |1    |\n","|2024-01-02T12:45:00|34.7728 |-87.6399 |-1.3   |1    |\n","|2024-01-02T12:50:00|34.7728 |-87.6399 |-1.3   |1    |\n","|2024-01-02T12:55:00|34.7728 |-87.6399 |-0.8   |1    |\n","+-------------------+--------+---------+-------+-----+\n","only showing top 5 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["[Stage 12:=====================================================> (98 + 2) / 100]\r"]},{"name":"stdout","output_type":"stream","text":["+-------------------+---------+---------+-------+-----+\n","|date               |latitude |longitude|dew_cel|dew_q|\n","+-------------------+---------+---------+-------+-----+\n","|2024-01-06T21:00:00|52.923353|4.780625 |-0.4   |1    |\n","|2024-01-06T21:06:00|52.923353|4.780625 |-1.0   |1    |\n","|2024-01-06T21:14:00|52.923353|4.780625 |-1.0   |1    |\n","|2024-01-06T21:25:00|52.923353|4.780625 |-1.0   |1    |\n","|2024-01-06T21:27:00|52.923353|4.780625 |-1.0   |1    |\n","+-------------------+---------+---------+-------+-----+\n","only showing top 5 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["#Check if the negative values remain\n","\n","df_f.where(F.col(\"tmp_cel\") < 0) \\\n","    .select(\"date\",\"latitude\",\"longitude\",\"tmp_cel\",\"tmp_q\") \\\n","    .show(5, False)\n","\n","df_f.where(F.col(\"dew_cel\") < 0) \\\n","    .select(\"date\",\"latitude\",\"longitude\",\"dew_cel\",\"dew_q\") \\\n","    .show(5, False)"]},{"cell_type":"markdown","id":"a2de4b4d","metadata":{},"source":["## Removal of Sentinel Values "]},{"cell_type":"code","execution_count":7,"id":"3f9ae6ce","metadata":{"scrolled":true},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Rows remaining after sentinel removal: 17,953,096\n"]},{"name":"stderr","output_type":"stream","text":["[Stage 19:======================================================>(99 + 1) / 100]\r"]},{"name":"stdout","output_type":"stream","text":["+-------------------+---------+---------+---------+-------+------+--------+---------+------+----------+-----+--------+------+-------+-----+-------+-----+-------+-----+\n","|date               |latitude |longitude|elevation|wnd_dir|wnd_q1|wnd_type|wnd_speed|wnd_q2|cig_height|cig_q|vis_dist|vis_q1|slp_val|slp_q|tmp_cel|tmp_q|dew_cel|dew_q|\n","+-------------------+---------+---------+---------+-------+------+--------+---------+------+----------+-----+--------+------+-------+-----+-------+-----+-------+-----+\n","|2024-01-01T00:00:00|52.923353|4.780625 |0.91     |220    |1     |N       |100      |1     |900       |1    |9000    |1     |9928   |1    |7.5    |1    |5.1    |1    |\n","|2024-01-01T01:00:00|52.923353|4.780625 |0.91     |220    |1     |N       |90       |1     |750       |1    |5000    |1     |9930   |1    |6.7    |1    |5.1    |1    |\n","|2024-01-01T02:00:00|52.923353|4.780625 |0.91     |230    |1     |N       |70       |1     |1200      |1    |16000   |1     |9928   |1    |8.7    |1    |6.1    |1    |\n","|2024-01-01T03:00:00|52.923353|4.780625 |0.91     |240    |1     |N       |100      |1     |960       |1    |17000   |1     |9932   |1    |8.7    |1    |6.0    |1    |\n","|2024-01-01T04:00:00|52.923353|4.780625 |0.91     |250    |1     |N       |90       |1     |630       |1    |16000   |1     |9935   |1    |8.7    |1    |6.1    |1    |\n","+-------------------+---------+---------+---------+-------+------+--------+---------+------+----------+-----+--------+------+-------+-----+-------+-----+-------+-----+\n","only showing top 5 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["# (1) Define sentinel values based on data documentation from the Federal Climate Complex \\n\n","# Data Documentation for Integrated Surface Data (ISD)\n","\n","removal_values = [\n","    '3', '7', '9', '99', '999', '9999', '99999', '999999',\n","    '+3', '+7', '+9', '+99', '+999', '+9999', '+99999', '+999999'\n","]\n","\n","# (2) Filtering: Keep rows where *no* column contains any of the sentinel values.\n","# We cast data to string because some columns are numeric.\n","\n","valid_conditions = [\n","    ~F.col(c).cast(\"string\").isin(removal_values)\n","    for c in df_f.columns\n","]\n","\n","combined_condition = reduce(lambda a, b: a & b, valid_conditions)\n","\n","# (3) Apply the filter\n","df_f = df_f.filter(combined_condition)\n","\n","# (4) Count rows after filtering (single pass)\n","row_count = df_f.count()\n","print(f\"Rows remaining after sentinel removal: {row_count:,}\")\n","\n","df_f.show(5, truncate=False)"]},{"cell_type":"markdown","id":"c4c7dbc8","metadata":{},"source":["### Mid-point Row Count Check\n","\n","Number of Rows Left: Final rows: 17,953,096 (removed 112,269,010 rows with sentinel values)\n"]},{"cell_type":"markdown","id":"bc8ba9b8","metadata":{},"source":["## Feature Engineering"]},{"cell_type":"code","execution_count":8,"id":"7e97ae6d","metadata":{},"outputs":[],"source":["# Convert DATE column to proper timestamp format\n","# Spark automatically parses standard formats like \"2024-03-25T14:00:00\"\n","df_f = df_f.withColumn(\"date\", F.to_timestamp(F.col(\"date\")))\n","df_f = df_f.withColumn(\"date_numeric\", F.datediff(F.col(\"date\"), F.lit(\"1970-01-01\")))\n","df_f = df_f.drop(\"date\")"]},{"cell_type":"code","execution_count":9,"id":"4cf6f40b","metadata":{},"outputs":[],"source":["# Creating column WND_SIN, WND_COS only is WND_DIR exists, otherwise fallback to raw data\n","if \"wnd_dir\" in df_f.columns and \"wnd_dir_sin\" not in df_f.columns and \"wnd_dir_cos\" not in df_f.columns:\n","    df_f = df_f.withColumn(\"wnd_dir\", F.col(\"wnd_dir\").cast(DoubleType()))\n","    rad = F.radians(F.col(\"wnd_dir\"))\n","    df_f = df_f.withColumn(\"wnd_dir_sin\", F.sin(rad)).withColumn(\"wnd_dir_cos\", F.cos(rad))\n","\n","# Converting to Standard metric hPa\n","if \"slp_val\" in df_f.columns and \"slp_hpa\" not in df_f.columns:\n","    df_f = df_f.withColumn(\"slp_hpa\", (F.col(\"slp_val\") / 10.0).cast(DoubleType()))"]},{"cell_type":"code","execution_count":10,"id":"485b0de4","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 23:======================================================>(99 + 1) / 100]\r"]},{"name":"stdout","output_type":"stream","text":["+---------+---------+---------+-------+------+--------+---------+------+----------+-----+--------+------+-------+-----+-------+-----+-------+-----+------------+-------------------+-------------------+-------+\n","|latitude |longitude|elevation|wnd_dir|wnd_q1|wnd_type|wnd_speed|wnd_q2|cig_height|cig_q|vis_dist|vis_q1|slp_val|slp_q|tmp_cel|tmp_q|dew_cel|dew_q|date_numeric|wnd_dir_sin        |wnd_dir_cos        |slp_hpa|\n","+---------+---------+---------+-------+------+--------+---------+------+----------+-----+--------+------+-------+-----+-------+-----+-------+-----+------------+-------------------+-------------------+-------+\n","|52.923353|4.780625 |0.91     |220.0  |1     |N       |100      |1     |900       |1    |9000    |1     |9928   |1    |7.5    |1    |5.1    |1    |19723       |-0.6427876096865393|-0.766044443118978 |992.8  |\n","|52.923353|4.780625 |0.91     |220.0  |1     |N       |90       |1     |750       |1    |5000    |1     |9930   |1    |6.7    |1    |5.1    |1    |19723       |-0.6427876096865393|-0.766044443118978 |993.0  |\n","|52.923353|4.780625 |0.91     |230.0  |1     |N       |70       |1     |1200      |1    |16000   |1     |9928   |1    |8.7    |1    |6.1    |1    |19723       |-0.7660444431189779|-0.6427876096865395|992.8  |\n","+---------+---------+---------+-------+------+--------+---------+------+----------+-----+--------+------+-------+-----+-------+-----+-------+-----+------------+-------------------+-------------------+-------+\n","only showing top 3 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["df_f.show(3, truncate=False)"]},{"cell_type":"code","execution_count":11,"id":"5e18d082","metadata":{},"outputs":[],"source":["#Optional Code for categorical columns\n","\n","#Only use categorical columns that exist and have non-null values\n","#CATEGORICAL_COLS = []\n","#for col in [\"wnd_type\"]:  # add more potential categorical cols here\n","#    if col in df_f.columns:\n","#        non_null_count = df_f.filter(F.col(col).isNotNull()).count()\n","#        if non_null_count > 0:\n","#            CATEGORICAL_COLS.append(col)\n","#            print(f\"Using categorical column: {col} ({non_null_count} non-null rows)\")\n","#        else:\n","#            print(f\"Skipping {col}: all values are null\")\n","#    else:\n","#        print(f\"Column {col} does not exist\")\n","\n","#print(f\"\\nFinal CATEGORICAL_COLS: {CATEGORICAL_COLS}\")"]},{"cell_type":"code","execution_count":12,"id":"dec720ef","metadata":{},"outputs":[],"source":["TARGET_COL = \"tmp_cel\"\n","FEATURE_COLS = [\n","    \"latitude\",\"longitude\",\"elevation\",\n","    \"dew_cel\",\"slp_hpa\",\"wnd_speed\",\"vis_dist\",\"cig_height\",\n","    \"date_numeric\"]\n","\n","ALL = [TARGET_COL] + FEATURE_COLS\n","\n","# # Finalised Dataset for Modeling\n","df_final = df_f.select([F.col(c).cast(\"double\").alias(c) for c in ALL])"]},{"cell_type":"markdown","id":"dd7b0f5b","metadata":{},"source":["## Saving the Dataset in Parquet Format for Subsequent ML Modeling "]},{"cell_type":"code","execution_count":13,"id":"6f4cf8a9","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["# Cleaned Dataset\n","df_final.write.mode(\"overwrite\").parquet(\"gs://dsa5208-mllib-proj/processed/df_cleaned.parquet\")"]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":5}